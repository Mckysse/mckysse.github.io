---
---


@inproceedings{chen-etal-2024-seeing,
    title = "Understanding and Modeling Human Label Variation in LLM â€” Natural Language Inference as A Case",
    author = "Chen, Beiduo",
    booktitle = "4th International Workshop on Dependability Modeling and Digitalization @ The 55th Annual IEEE/IFIP International Conference on Dependable Systems and Networks",
    year = "2025",
    month = "jun",
    address = "Naples, Italy",
    abstract = "In this talk, I will discuss the phenomenon of human label variation and its implications for the reliability of large language models (LLMs). Traditionally, models are trained to focus on a single ``correc'' answer, but real-world scenarios are rarely black and white-often, multiple plausible answers exist. For instance, in natural language inference (NLI) tasks, annotators frequently disagree on whether a given statement entails, contradicts, or remains neutral with respect to another. Drawing from my recent research, I will explore how analyzing inference task examples and leveraging human or LLM-generated explanations can enhance our understanding and modeling of human label variation. By addressing this variation, we aim to improve model comprehension of disputed judgments, enrich its evaluation of uncertainty and confidence, and ultimately contribute to more robust and reliable LLMs for real-world applications.",
    slides={WDMD2025_HLV_talk.pdf},
    preview={WDMD2025_Talk_HLV_preview.png}
}

